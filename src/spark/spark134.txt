第134讲 spark到底解决了什么根本性技术问题
hadoop存在的问题数据从HDFS上加载数据,然后再处理,最后再写入到HDFS上
虽然后来出现了TEG框架,使用DAG,将数据流中不同步骤的计算,构成了一个有向无环图,但是基于数据流的DAG,实现了任务的调度和故障恢复,但是每次操作依然读写磁盘。
同样的操作,如果第二次运算的话,还是和第一次一样,操作读写磁盘。每次查询都要重新加载,因此带来了性能开销。
机器学习，图运算,在大规模的频繁使用迭代算法
交互式的数据挖掘,用户反复查询具体数据的子集

因此Spark解决方案就是使用RDD,弹性分布式数据集,TDD可以将工作机显式的将工作集缓存在内存中,后续查询可以重用工作集的结果,这就极大的提高了查询速度。
RDD本身提供了共享内存模型:
RDD有前后的依赖关系,即每一个RDD都是由上一个RDD产生的,例如通过join或者map等操作,当中间有一个失败的时候,可以再失败的前一个步骤上进行恢复数据。只要前一个RDD被缓存了,都可以从该RDD上重新计算。
带来了极好的容错和极高的效率。

------------------------------------------------------------------------------------------------
第135讲 spark在BAT的深入应用
------------------------------------------------------------------------------------------------
第136讲 spark

