第134讲 spark到底解决了什么根本性技术问题
hadoop存在的问题数据从HDFS上加载数据,然后再处理,最后再写入到HDFS上
虽然后来出现了TEG框架,使用DAG,将数据流中不同步骤的计算,构成了一个有向无环图,但是基于数据流的DAG,实现了任务的调度和故障恢复,但是每次操作依然读写磁盘。
同样的操作,如果第二次运算的话,还是和第一次一样,操作读写磁盘。每次查询都要重新加载,因此带来了性能开销。
机器学习，图运算,在大规模的频繁使用迭代算法
交互式的数据挖掘,用户反复查询具体数据的子集

因此Spark解决方案就是使用RDD,弹性分布式数据集,TDD可以将工作机显式的将工作集缓存在内存中,后续查询可以重用工作集的结果,这就极大的提高了查询速度。
RDD本身提供了共享内存模型:
RDD有前后的依赖关系,即每一个RDD都是由上一个RDD产生的,例如通过join或者map等操作,当中间有一个失败的时候,可以再失败的前一个步骤上进行恢复数据。只要前一个RDD被缓存了,都可以从该RDD上重新计算。
带来了极好的容错和极高的效率。

------------------------------------------------------------------------------------------------
第135讲 spark在BAT的深入应用
------------------------------------------------------------------------------------------------
第136讲 spark

------------------------------------------------------------------------------------------------
第143讲：Spark RDD中Runtime流程解析

------------------------------------------------------------------------------------------------
第144讲：Spark RDD中Transformation的map、flatMap、mapPartitions、glom详解
1.map
 就是接受一个函数,将T转换成U的过程,仅仅是转换,一个partition的一条记录进行一次转换。
2flatMap
 也是map,只是将最后的结果成一个大集合
3.mapPartitions
  接受的函数是一个partition,该函数处理整个partition,例如如果操作数据库,那么就在该地方使用连接数据库,因此可以使一个partition共享一个数据库连接。
4.glom
 将partition的数据转换成Array[T],即一个partition的数据最终转换成一个数组
------------------------------------------------------------------------------------------------
第145讲：